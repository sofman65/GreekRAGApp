# Î•ÏÎ¼Î®Ï‚ (Hermes) - Backend API

FastAPI backend for the Greek Army RAG (Retrieval-Augmented Generation) system.

## ğŸ“‹ Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Configuration](#configuration)
- [Running the Server](#running-the-server)
- [API Documentation](#api-documentation)
- [Project Structure](#project-structure)

## âœ¨ Features

- ğŸš€ FastAPI-based REST API
- ğŸ” JWT authentication
- ğŸ’¬ WebSocket support for streaming responses
- ğŸ“š RAG system with Weaviate vector database
- ğŸ¤– Integration with Ollama for LLM and embeddings
- ğŸ“„ Document ingestion (PDF, Markdown)
- ğŸ¯ Greek language optimized

## ğŸ—ï¸ Architecture

```
Backend Architecture:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI App   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Auth Routes    â”‚
â”‚  Query Routes   â”‚
â”‚  Upload Routes  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  RAG Service    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Embeddings     â”‚â—„â”€â”€â–º Ollama
â”‚  Vector DB      â”‚â—„â”€â”€â–º Weaviate
â”‚  LLM Provider   â”‚â—„â”€â”€â–º Ollama
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Prerequisites

### Required Services

1. **Python 3.10+**
2. **Ollama** - Local LLM inference
   ```bash
   # Install Ollama from https://ollama.ai
   # Pull required models:
   ollama pull llama3.2
   ollama pull nomic-embed-text
   ```

3. **Weaviate** - Vector database
   ```bash
   docker run -d \
     -p 8080:8080 \
     -e AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true \
     -e PERSISTENCE_DATA_PATH=/var/lib/weaviate \
     semitechnologies/weaviate:latest
   ```

## ğŸš€ Installation

### 1. Setup Script (Recommended)

```bash
cd backend
chmod +x scripts/setup.sh
./scripts/setup.sh
```

### 2. Manual Installation

```bash
cd backend

# Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Create environment file
cp env.example .env

# Create necessary directories
mkdir -p data/corpus logs
```

## âš™ï¸ Configuration

### Environment Variables

Edit `.env` file:

```bash
# Server
HOST=0.0.0.0
PORT=8000
DEBUG=False

# Security (CHANGE IN PRODUCTION!)
SECRET_KEY=your-secret-key-here

# Services
WEAVIATE_URL=http://localhost:8080
OLLAMA_BASE_URL=http://localhost:11434
```

### RAG Configuration

Edit `config/config.yml`:

```yaml
corpus:
  input_dir: "backend/data/corpus"
  file_types: [".pdf", ".md"]

embeddings:
  provider: "ollama"
  model: "nomic-embed-text"

llm:
  provider: "ollama"
  model: "llama3.2"
  temperature: 0.1
```

## ğŸƒ Running the Server

### Development Mode

```bash
# Using startup script
./scripts/start.sh

# Or manually
python -m uvicorn main:app --reload --port 8000
```

### Production Mode

```bash
python -m uvicorn main:app --host 0.0.0.0 --port 8000 --workers 4
```

The API will be available at:
- **API**: http://localhost:8000
- **Docs**: http://localhost:8000/api/docs
- **ReDoc**: http://localhost:8000/api/redoc

## ğŸ“„ Document Ingestion

### 1. Add Documents

Place your documents in `backend/data/corpus/`:
```bash
backend/data/corpus/
  â”œâ”€â”€ regulation-1.pdf
  â”œâ”€â”€ regulation-2.md
  â””â”€â”€ ...
```

### 2. Run Ingestion

```bash
python scripts/ingest.py
```

This will:
- Load documents from corpus directory
- Split them into chunks
- Generate embeddings
- Store in Weaviate

## ğŸ”Œ API Documentation

### Authentication

#### Register
```bash
POST /api/auth/signup
{
  "username": "user",
  "password": "password",
  "full_name": "Full Name"
}
```

#### Login
```bash
POST /api/auth/login
Content-Type: application/x-www-form-urlencoded

username=admin&password=1234
```

Response:
```json
{
  "access_token": "eyJ...",
  "token_type": "bearer",
  "user": {
    "username": "admin",
    "full_name": "Î”Î¹Î±Ï‡ÎµÎ¹ÏÎ¹ÏƒÏ„Î®Ï‚",
    "role": "admin"
  }
}
```

### Query Endpoints

#### Non-streaming Query
```bash
POST /api/query
{
  "question": "Î Î¿Î¹ÎµÏ‚ ÎµÎ¯Î½Î±Î¹ Î¿Î¹ Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯ÎµÏ‚ Î³Î¹Î± Î¬Î´ÎµÎ¹Î±;"
}
```

Response:
```json
{
  "answer": "Î£ÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ Ï„Î¿Î½ ÎºÎ±Î½Î¿Î½Î¹ÏƒÎ¼ÏŒ...",
  "sources": [
    {
      "text": "...",
      "score": 0.95,
      "source": "regulation-1.pdf"
    }
  ]
}
```

#### WebSocket Streaming
```javascript
const ws = new WebSocket('ws://localhost:8000/api/ws/chat');

ws.send(JSON.stringify({
  question: "Î ÏÏ‚ ÎµÏ†Î±ÏÎ¼ÏŒÎ¶Î¿Î½Ï„Î±Î¹ Î¿Î¹ ÎºÎ±Î½Î¿Î½Î¹ÏƒÎ¼Î¿Î¯;"
}));

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  // data.type: "sources" | "token" | "done" | "error"
};
```

### Health Check
```bash
GET /api/health
```

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ auth.py         # Authentication endpoints
â”‚   â”‚       â”œâ”€â”€ query.py        # RAG query endpoints
â”‚   â”‚       â”œâ”€â”€ health.py       # Health checks
â”‚   â”‚       â””â”€â”€ upload.py       # Document upload
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py           # Application settings
â”‚   â”‚   â””â”€â”€ security.py         # JWT & password handling
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ auth.py             # Auth models
â”‚   â”‚   â””â”€â”€ query.py            # Query models
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ rag_service.py      # Main RAG orchestration
â”‚       â”œâ”€â”€ embeddings.py       # Embedding generation
â”‚       â”œâ”€â”€ llm_providers.py    # LLM integration
â”‚       â”œâ”€â”€ vectordb.py         # Weaviate client
â”‚       â”œâ”€â”€ loaders.py          # Document loaders
â”‚       â”œâ”€â”€ splitter.py         # Text chunking
â”‚       â””â”€â”€ utils.py            # Utilities
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yml              # RAG configuration
â”œâ”€â”€ data/
â”‚   â””â”€â”€ corpus/                 # Document storage
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.sh                # Setup script
â”‚   â”œâ”€â”€ start.sh                # Startup script
â”‚   â””â”€â”€ ingest.py               # Document ingestion
â”œâ”€â”€ env.example                 # Environment template
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸ”’ Security Notes

1. **Change SECRET_KEY** in production
2. Use **HTTPS** in production
3. Implement **rate limiting** for public deployments
4. Use **proper database** instead of in-memory user storage
5. Enable **CORS** only for trusted origins

## ğŸ› Troubleshooting

### Weaviate Connection Error
```bash
# Check if Weaviate is running
curl http://localhost:8080/v1/meta

# Restart Weaviate
docker restart <weaviate-container-id>
```

### Ollama Connection Error
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama service
ollama serve
```

### Module Import Errors
```bash
# Ensure PYTHONPATH is set
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# Reinstall dependencies
pip install -r requirements.txt
```

## ğŸ“ Default Credentials

- **Username**: `admin`
- **Password**: `1234`

âš ï¸ Change these in production!

## ğŸ¤ Contributing

This is an internal military system. Contributions should follow security protocols.

## ğŸ“„ License

Internal use only - Greek Armed Forces

---

Made with ğŸ‡¬ğŸ‡· for the Hellenic Armed Forces

